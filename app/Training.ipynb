{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1304 images\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('E Horizontalonius', 178),\n",
       " ('A Retusus', 175),\n",
       " ('A Myriostigma', 163),\n",
       " ('Th Bicolor', 40),\n",
       " ('A Kotschoubeyanus', 33),\n",
       " ('L Williamsii', 28),\n",
       " ('S Disciformis', 27),\n",
       " ('R Beguinii', 26),\n",
       " ('A valdezii', 24),\n",
       " ('C humilis', 24),\n",
       " ('H curvispinus', 23),\n",
       " ('N Conoidea', 23),\n",
       " ('Th Heterochromus', 23),\n",
       " ('A Trigonus', 22),\n",
       " ('H kunzei', 22),\n",
       " ('N subgibbosa', 22),\n",
       " ('Ef ochoterenaus', 21),\n",
       " ('H heinrichianus', 20),\n",
       " ('Lobivia pampana', 20),\n",
       " ('Th esmeraldana', 20),\n",
       " ('A lloydii', 19),\n",
       " ('C Echinus', 19),\n",
       " ('Ep Greggii', 19),\n",
       " ('H limariensis', 19),\n",
       " ('H Texensis', 19),\n",
       " ('T nikolae', 18),\n",
       " ('Th Multicephalus', 18),\n",
       " ('Thelocephala challensis', 18),\n",
       " ('A ritteri', 17),\n",
       " ('M Candida', 17),\n",
       " ('N senilis', 17),\n",
       " ('T Valdezianus', 17),\n",
       " ('A Fissuratus', 16),\n",
       " ('Th Hex', 16),\n",
       " ('Th lloydii', 16),\n",
       " ('A Coahuilense', 15),\n",
       " ('A scaphar', 15),\n",
       " ('Ec Pectinatus', 15),\n",
       " ('H taltalensis', 15),\n",
       " ('M lasiacantha', 15),\n",
       " ('Th napina', 15),\n",
       " ('Thelocephala glabrescens', 15)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "\n",
    "TRAIN_DIR = '../res/Proper'\n",
    "MODELS_DIR = '/Models'\n",
    "IMG_SIZE_X = 320\n",
    "IMG_SIZE_Y = 240\n",
    "LR = 1e-3\n",
    "labels = os.listdir(TRAIN_DIR)\n",
    "LABELS_COUNT = len(labels)\n",
    "MODEL_NAME = 'cactusifier-{}-{}-{}-16conv2filter2size-notaugmented-15tr-byte-002.model'.format(LR, '2conv-basic','treshold_20')\n",
    "\n",
    "labelCounts = {}\n",
    "for directory in labels:\n",
    "    files = os.listdir(os.path.join(TRAIN_DIR, directory))\n",
    "    labelCounts[directory] = len(files)\n",
    "\n",
    "print(sum(labelCounts.values()), 'images')\n",
    "labelCounts = sorted(labelCounts.items(), key=operator.itemgetter(1), reverse = True)\n",
    "labelCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hot_one_encoded_label(label):\n",
    "    h1e = np.zeros(LABELS_COUNT)\n",
    "    h1e[labels.index(label)] = 1\n",
    "    return h1e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_from_h1e(h1e):\n",
    "    index = np.where(h1e == 1)[0][0]\n",
    "    return labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_from_index(index):\n",
    "    return labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_data():\n",
    "    training_data = []\n",
    "    counter = 0\n",
    "    for directory in labels:\n",
    "        print(counter, directory)\n",
    "        labelDirectory = os.path.join(TRAIN_DIR, directory)\n",
    "        files = os.listdir(labelDirectory)\n",
    "        for img in files:\n",
    "            label = get_hot_one_encoded_label(directory)\n",
    "            path = os.path.join(labelDirectory, img)\n",
    "            try:\n",
    "                img = cv2.resize(cv2.imread(path, cv2.IMREAD_COLOR), (IMG_SIZE_X, IMG_SIZE_Y))\n",
    "            except Exception as e:\n",
    "                print(path)\n",
    "                print(str(e))\n",
    "            training_data.append([np.array(img), np.array(label)])\n",
    "            #training_data.append([np.divide(np.array(img), 255), np.array(label)])\n",
    "        counter = counter + 1\n",
    "    print('Shuffling')\n",
    "    shuffle(training_data)\n",
    "    print('Saving')\n",
    "    #np.save('train_data.npy', training_data)\n",
    "    print('Done!')\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 A Coahuilense\n",
      "1 A Fissuratus\n",
      "2 A Kotschoubeyanus\n",
      "3 A lloydii\n",
      "4 A Myriostigma\n",
      "5 A Retusus\n",
      "6 A ritteri\n",
      "7 A scaphar\n",
      "8 A Trigonus\n",
      "9 A valdezii\n",
      "10 C Echinus\n",
      "11 C humilis\n",
      "12 E Horizontalonius\n",
      "13 Ec Pectinatus\n",
      "14 Ef ochoterenaus\n",
      "15 Ep Greggii\n",
      "16 H curvispinus\n",
      "17 H heinrichianus\n",
      "18 H kunzei\n",
      "19 H limariensis\n",
      "20 H taltalensis\n",
      "21 H Texensis\n",
      "22 L Williamsii\n",
      "23 Lobivia pampana\n",
      "24 M Candida\n",
      "25 M lasiacantha\n",
      "26 N Conoidea\n",
      "27 N senilis\n",
      "28 N subgibbosa\n",
      "29 R Beguinii\n",
      "30 S Disciformis\n",
      "31 T nikolae\n",
      "32 T Valdezianus\n",
      "33 Th Bicolor\n",
      "34 Th esmeraldana\n",
      "35 Th Heterochromus\n",
      "36 Th Hex\n",
      "37 Th lloydii\n",
      "38 Th Multicephalus\n",
      "39 Th napina\n",
      "40 Thelocephala challensis\n",
      "41 Thelocephala glabrescens\n",
      "Shuffling\n",
      "Saving\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_data = create_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From E:\\Programs\\Anaconda3\\lib\\site-packages\\tflearn\\initializations.py:119: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "WARNING:tensorflow:From E:\\Programs\\Anaconda3\\lib\\site-packages\\tflearn\\objectives.py:66: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "convnet = input_data(shape=[None, IMG_SIZE_X, IMG_SIZE_Y, 3], name='input')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, LABELS_COUNT, activation='softmax')\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir='log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from E:\\Programming\\Python\\Cactusifier\\app\\cactusifier-0.001-2conv-basic-treshold_20-16conv2filter2size-notaugmented-15tr-byte-002.model\n",
      "Model cactusifier-0.001-2conv-basic-treshold_20-16conv2filter2size-notaugmented-15tr-byte-002.model loaded!\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('{}.meta'.format(MODEL_NAME)):\n",
    "    model.load(MODEL_NAME)\n",
    "    print(\"Model\", MODEL_NAME, \"loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainCountRatio = 0.8\n",
    "trainSize = int(round(len(train_data)*trainCountRatio))\n",
    "test = train_data[:-trainSize]\n",
    "train = train_data[-trainSize:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([i[0] for i in train]).reshape(-1, IMG_SIZE_X, IMG_SIZE_Y, 3)\n",
    "Y = [i[1] for i in train]\n",
    "\n",
    "test_x = np.array([i[0] for i in test]).reshape(-1, IMG_SIZE_X, IMG_SIZE_Y, 3)\n",
    "test_y = [i[1] for i in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 2175  | total loss: 2.00944 | time: 9.658s\n",
      "| Adam | epoch: 128 | loss: 2.00944 - acc: 0.4337 -- iter: 1024/1043\n",
      "Training Step: 2176  | total loss: 1.99365 | time: 14.577s\n",
      "| Adam | epoch: 128 | loss: 1.99365 - acc: 0.4294 | val_loss: 4.92961 - val_acc: 0.1379 -- iter: 1043/1043\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "for i in range(300):\n",
    "    model.fit({'input': X}, {'targets': Y}, n_epoch=10, validation_set=({'input': test_x}, {'targets': test_y}), \n",
    "        snapshot_step=500, show_metric=True, run_id=MODEL_NAME)\n",
    "    model.save(MODEL_NAME)\n",
    "\n",
    "##################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:E:\\Programming\\Python\\Cactusifier\\app\\cactusifier-0.001-2conv-basic-treshold_20-16conv2filter2size.model is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "model.save(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A scaphar 6.09%\n",
      "A valdezii 7.61%\n",
      "Th Multicephalus 9.25%\n",
      "H Texensis 14.67%\n",
      "A Kotschoubeyanus 18.58%\n"
     ]
    }
   ],
   "source": [
    "TEST_PATH = '../res/Test'\n",
    "TEST_SAMPLE_PATH = os.path.join(TEST_PATH, 'aretusus2.jpg')\n",
    "testImage = np.array(cv2.resize(cv2.imread(TEST_SAMPLE_PATH, cv2.IMREAD_COLOR), (IMG_SIZE_X, IMG_SIZE_Y)))\n",
    "#testImage = np.divide(np.array(cv2.resize(cv2.imread(TEST_SAMPLE_PATH, cv2.IMREAD_COLOR), (IMG_SIZE_X, IMG_SIZE_Y))), 255)\n",
    "testImage = testImage.reshape(-1, IMG_SIZE_X, IMG_SIZE_Y, 3)\n",
    "result = model.predict(testImage)\n",
    "s = sorted(enumerate(result[0]), key=lambda x: x[1])\n",
    "bestMatches = s[-5:]\n",
    "for match in bestMatches:\n",
    "    print(get_label_from_index(match[0]), str(round(match[1]*100, 2)) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard --logdir=foo:E:\\Programming\\Python\\Cactusifier\\app\\log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
