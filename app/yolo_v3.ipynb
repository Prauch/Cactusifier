{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "_ANCHORS = [(10, 13), (16, 30), (33, 23), (30, 61), (62, 45), (59, 119), (116, 90), (156, 198), (373, 326)]\n",
    "_BATCH_NORM_DECAY = 0.9\n",
    "_BATCH_NORM_EPSILON = 1e-05\n",
    "_LEAKY_RELU = 0.1\n",
    "\n",
    "def darknet53(inputs):\n",
    "    inputs = _conv2d_fixed_padding(inputs, 32, 3)\n",
    "    inputs = _conv2d_fixed_padding(inputs, 64, 3, strides=2)\n",
    "    inputs = _darknet53_block(inputs, 32)\n",
    "    inputs = _conv2d_fixed_padding(inputs, 128, 3, strides=2)\n",
    "    \n",
    "    for i in range(2):\n",
    "        inputs = _darknet53_block(inputs, 64)\n",
    "    \n",
    "    inputs = _conv2d_fixed_padding(inputs, 256, 3, strides=2)\n",
    "    \n",
    "    for i in range(8):\n",
    "        inputs = _darknet53_block(inputs, 128)\n",
    "    route1 = inputs\n",
    "    inputs = _conv2d_fixed_padding(inputs, 512, 3, strides=2)\n",
    "    \n",
    "    for i in range(8):\n",
    "        inputs = _darknet53_block(inputs, 256)\n",
    "    route2 = inputs\n",
    "    inputs = _conv2d_fixed_padding(inputs, 1024, 3, strides=2)\n",
    "    \n",
    "    for i in range(4):\n",
    "        inputs = _darknet53_block(inputs, 512)\n",
    "    return route1, route2, inputs\n",
    "\n",
    "def _darknet53_block(inputs, filters):\n",
    "    shortcut = inputs\n",
    "    inputs = _conv2d_fixed_padding(inputs, filters, 1)\n",
    "    inputs = _conv2d_fixed_padding(inputs, filters*2, 3)\n",
    "    \n",
    "    inputs = inputs + shortcut\n",
    "    return inputs\n",
    "\n",
    "def yolo_v3(inputs, num_classes, is_training=False, data_format='NCHW', reuse=False):\n",
    "    if data_format=='NCHW':\n",
    "        inputs = tf.transpose(inputs, [0, 3, 1, 2])\n",
    "    inputs = inputs/255\n",
    "    batch_norm_params = {\n",
    "        'decay': _BATCH_NORM_DECAY,\n",
    "        'epsilon': _BATCH_NORM_EPSILON,\n",
    "        'scale': True,\n",
    "        'is_training': is_training,\n",
    "        'fused': None\n",
    "    }\n",
    "    \n",
    "    with slim.arg_scope([slim.conv2d, slim.batch_norm, _fixed_padding], data_format=data_format, reuse=reuse):\n",
    "        with slim.arg_scope([slim.conv2d], normalizer_fn=slim.batch_norm, normalizer_params=batch_norm_params, biases_initializer=None, activation_fn=lambda x: tf.nn.leaky_relu(x, alpha=_LEAKY_RELU)):\n",
    "            with tf.variable_scope('darknet-53'):\n",
    "                inputs = darknet53(inputs)\n",
    "    \n",
    "    with tf.variable_scope('darknet-53'):\n",
    "        route_1, route_2, inputs = darknet53(inputs)\n",
    "        \n",
    "    with tf.variable_scope('yolo-v3'):\n",
    "        route, inputs = _yolo_block(inputs, 512)\n",
    "        detect_1 = _detection_layer(inputs, num_classes, _ANCHORS[6:9], img_size, data_format)\n",
    "        detect_1 = tf.identity(detect_1, name='detect_1')\n",
    "        \n",
    "        inputs = _conv2d_fixed_padding(route, 256, 1)\n",
    "        upsample_size = route_2.get_shape().as_list()\n",
    "        inputs = _upsample(inputs, upsample_size, data_format)\n",
    "        inputs = tf.concat([inputs, route_2], axis=1 if data_format=='NCHW' else 3)\n",
    "        \n",
    "        route, inputs = _yolo_block(inputs, 256)\n",
    "        detect_2 = _detection_layer(inputs, num_classes, _ANCHORS[3:6], img_size, data_format)\n",
    "        detect_2 = tf.identity(detect_2, name='detect_2')\n",
    "       \n",
    "        inputs = _conv2d_fixed_padding(route, 128, 1)\n",
    "        upsample_size = route_1.get_shape().as_list()\n",
    "        inputs = _upsample(inputs, upsample_size, data_format)\n",
    "        inputs = tf.concat([inputs, route_1], axis=1 if data_format=='NCHW' else 3)\n",
    "        \n",
    "        _, inputs = _yolo_block(inputs, 128)\n",
    "        \n",
    "        detect_3 = _detection_layer(inputs, num_classes, _ANCHORS[0:3], img_size, data_format)\n",
    "        detect_3 = tf.identity(detect_3, name='detect_3')\n",
    "        \n",
    "        detections = tf.concat([detect_1, detect_2, detect_3], axis=1)\n",
    "        return detections\n",
    "\n",
    "def _yolo_block(inputs, filters):\n",
    "    inputs = _conv2d_fixed_padding(inputs, filters, 1)\n",
    "    inputs = _conv2d_fixed_padding(inputs, filters*2, 3)\n",
    "    inputs = _conv2d_fixed_padding(inputs, filters, 1)\n",
    "    inputs = _conv2d_fixed_padding(inputs, filters*2, 3)\n",
    "    inputs = _conv2d_fixed_padding(inputs, filters, 1)\n",
    "    \n",
    "    route = inputs\n",
    "    inputs = _conv2d_fixed_padding(inputs, filters*2, 3)\n",
    "    return route, inputs\n",
    "\n",
    "def _detection_layer(inputs, num_classes, anchors, img_size, data_format):\n",
    "    num_anchors = len(anchors)\n",
    "    predictions = slim.conv2d(inputs, num_anchors * (5 + num_classes), 1, stride=1, normalizer_fn=None, activation_fn=None, biases_initializer=tf.zeros_initializer())\n",
    "    shape = predictions.get_shape().as_list()\n",
    "    grid_size = _get_size(shape, data_format)\n",
    "    dim = grid_size[0] * grid_size[1]\n",
    "    bbox_attrs = 5 + num_classes\n",
    "    \n",
    "    if data_format=='NCHW':\n",
    "        predictions = tf.reshape(predictions, [-1, num_anchors * bbox_attrs, dim])\n",
    "        predictions = tf.transpose(predictions, [0, 2, 1])\n",
    "    \n",
    "    predictions = tf.reshape(predictions, [-1, num_anchors * dim, bbox_attrs])\n",
    "    stride = (img_size[0] // grid_size[0], img_size[1] // grid_size[1])\n",
    "    anchors = [(a[0] / stride[0], a[1] / stride[1]) for a in anchors]\n",
    "    \n",
    "    box_centers, box_sizes, confidence, classes = tf.split(predictions, [2, 2, 1, num_classes], axis=1)\n",
    "    box_centers = tf.nn.sigmoid(box_centers)\n",
    "    confidence = tf.nn.sigmoid(confidence)\n",
    "    \n",
    "    grid_x = tf.range(grid_size[0], dtype=tf.float32)\n",
    "    grid_y = tf.range(grid_size[1], dtype=tf.float32)\n",
    "    a,b = tf.meshgrid(grid_x, grid_y)\n",
    "    \n",
    "    x_offset = tf.reshape(a, (-1, 1))\n",
    "    y_offset = tf.reshape(b, (-1, 1))\n",
    "    \n",
    "    x_y_offset = tf.concat([x_offset, y_offset], axis=-1)\n",
    "    x_y_offset = tf.reshape(tf.tile(x_y_offset, [1, num_anchors]), [1, -1, 2])\n",
    "    \n",
    "    box_centers = box_centers + x_y_offset\n",
    "    box_centers = box_centers * stride\n",
    "    \n",
    "    anchors = tf.tile(anchors, [dim, 1])\n",
    "    box_sizes = tf.exp(box_sizes)*anchors\n",
    "    box_sizes = box_sizes * stride\n",
    "    \n",
    "    detections = tf.concat([box_centers, box_sizes, confidence], axis=-1)\n",
    "    \n",
    "    classes = tf.nn.sigmoid(classes)\n",
    "    predictions = tf.concat([detections, classes], axis=-1)\n",
    "    return predictions\n",
    "\n",
    "def load_weights(var_list, weights_file):\n",
    "    with open(weights_file, \"rb\") as fp:\n",
    "        _ = np.fromfile(fp, dtype=np.int32, count=5)   \n",
    "        weights = np.fromfile(fp, dtype=np.float32)\n",
    "        \n",
    "    \n",
    "\n",
    "def _get_size(shape, data_format):\n",
    "    if len(shape) == 4:\n",
    "        shape = shape[1:]\n",
    "    return shape[1:3] if data_format == 'NCHW' else shape[0:2]\n",
    "\n",
    "def _upsample_org(inputs, out_shape, data_format='NCHW'):\n",
    "    inputs = _fixed_padding(inputs, 3, mode='SYMMETRIC')\n",
    "    if data_format=='NCHW':\n",
    "        inputs = tf.transpose(inputs, [0, 2, 3, 1])\n",
    "    if data_format=='NCHW':\n",
    "        height = out_shape[3]\n",
    "        width = out_shape[2]\n",
    "    else:\n",
    "        height = out_shape[2]\n",
    "        width = out_shape[1]\n",
    "        \n",
    "    new_height = height + 4\n",
    "    new_width = width + 4\n",
    "    \n",
    "    inputs = tf.image.resize_bilinear(inputs, (new_height, new_width))\n",
    "    inputs = inputs[:, 2:-2, 2:-2, :]\n",
    "    if data_format=='NCHW':\n",
    "        inputs = tf.transpose(inputs, [0, 3, 1, 2])\n",
    "    inputs = tf.identity(inputs, name='upsampled')\n",
    "    return inputs\n",
    "\n",
    "def _upsample(inputs, out_shape, data_format='NCHW'):\n",
    "    if data_format == 'NCHW':\n",
    "        inputs = tf.transpose(inputs, [0, 2, 3, 1])\n",
    "\n",
    "    if data_format == 'NCHW':\n",
    "        new_height = out_shape[3]\n",
    "        new_width = out_shape[2]\n",
    "    else:\n",
    "        new_height = out_shape[2]\n",
    "        new_width = out_shape[1]\n",
    "\n",
    "    inputs = tf.image.resize_nearest_neighbor(inputs, (new_height, new_width))\n",
    "    if data_format == 'NCHW':\n",
    "        inputs = tf.transpose(inputs, [0, 3, 1, 2])\n",
    "\n",
    "    inputs = tf.identity(inputs, name='upsampled')\n",
    "    return inputs\n",
    "\n",
    "@tf.contrib.framework.add_arg_scope\n",
    "def _fixed_padding(inputs, kernel_size, *args, mode='CONSTANT', **kwargs):\n",
    "    \"\"\"\n",
    "    Pads the input along the spatial dimensions independently of input size.\n",
    "\n",
    "    Args:\n",
    "      inputs: A tensor of size [batch, channels, height_in, width_in] or\n",
    "        [batch, height_in, width_in, channels] depending on data_format.\n",
    "      kernel_size: The kernel to be used in the conv2d or max_pool2d operation.\n",
    "                   Should be a positive integer.\n",
    "      data_format: The input format ('NHWC' or 'NCHW').\n",
    "      mode: The mode for tf.pad.\n",
    "\n",
    "    Returns:\n",
    "      A tensor with the same format as the input with the data either intact\n",
    "      (if kernel_size == 1) or padded (if kernel_size > 1).\n",
    "    \"\"\"\n",
    "    pad_total = kernel_size - 1\n",
    "    pad_beg = pad_total // 2\n",
    "    pad_end = pad_total - pad_beg\n",
    "\n",
    "    if kwargs['data_format'] == 'NCHW':\n",
    "        padded_inputs = tf.pad(inputs, [[0, 0], [0, 0],\n",
    "                                        [pad_beg, pad_end], [pad_beg, pad_end]], mode=mode)\n",
    "    else:\n",
    "        padded_inputs = tf.pad(inputs, [[0, 0], [pad_beg, pad_end],\n",
    "                                        [pad_beg, pad_end], [0, 0]], mode=mode)\n",
    "    return padded_inputs\n",
    "\n",
    "def _conv2d_fixed_padding(inputs, filters, kernel_size, strides=1):\n",
    "    if strides > 1:\n",
    "        inputs = _fixed_padding(inputs, kernel_size)\n",
    "    inputs = slim.conv2d(inputs, filters, kernel_size, stride=strides, padding=('SAME' if strides == 1 else 'VALID'))\n",
    "    return inputs;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
